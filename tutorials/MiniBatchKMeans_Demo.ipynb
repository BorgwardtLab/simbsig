{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdMO6zbMbIcB"
   },
   "source": [
    "# MiniBatchKMeans Demo\n",
    "This demo illustrates how SIMBSIG can be used for MiniBatchKMeans, and how the use compares to scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simbsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1655383392748,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "7AbLEIDAaoBZ"
   },
   "outputs": [],
   "source": [
    "from simbsig.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import MiniBatchKMeans as MiniBatchKMeans_sk\n",
    "import h5py as h5py\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN436qeJaqbP"
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1655383392748,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "YhjxgUO_b_Ib"
   },
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "trn_pts_per_cluster = 10\n",
    "query_pts_per_cluster = 5\n",
    "n_dim = 2\n",
    "rng = np.random.RandomState(42)\n",
    "centers = rng.uniform(low=-20,high=20,size=(n_clusters,n_dim))\n",
    "centers_init = rng.uniform(low=-20,high=20,size=(n_clusters,n_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort cluster centers by first coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_centers(centers):\n",
    "    sorted_idxs = np.argsort(centers[:,0],axis=0)\n",
    "    return centers[sorted_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fInMHdVicL73"
   },
   "source": [
    "## Create Toy Data\n",
    "### numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1655383409809,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "JnsKWphqcQDd"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = make_blobs(n_samples=n_clusters * trn_pts_per_cluster, centers=centers, n_features=n_dim,\n",
    "                              random_state=42)\n",
    "\n",
    "X_query, y_query = make_blobs(n_samples=n_clusters * query_pts_per_cluster, centers=centers, n_features=n_dim,\n",
    "                              random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcS7CtbnCawH"
   },
   "source": [
    "### hdf5 files\n",
    "If you work from your computer, you can execute the statement below:\n",
    "Of course you can also store the data in a directory more suitable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working from your computer, your disk can be used to save and read data\n",
    "import os\n",
    "dataset_path = os.path.dirname(os.path.realpath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1655383418144,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "I4fuN3KnCN6h",
    "outputId": "bd76399a-0dd0-41f7-93af-9697a17c43bc"
   },
   "outputs": [],
   "source": [
    "# hdf5 files using h5py\n",
    "train_file = f'train.hdf5'\n",
    "query_file = f'query.hdf5'\n",
    "\n",
    "with h5py.File(os.path.join(dataset_path, f\"{train_file}\"), 'w') as f:\n",
    "    f.create_dataset(\"X\", data=X_train)\n",
    "\n",
    "with h5py.File(os.path.join(dataset_path, f\"{query_file}\"), 'w') as f:\n",
    "    f.create_dataset(\"X\", data=X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSm9Qw5hcpf8"
   },
   "source": [
    "## Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1655383421955,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "Snfeo9fycUIr",
    "outputId": "f95249f8-e444-4a86-87da-10ec95dd6611"
   },
   "outputs": [],
   "source": [
    "mbkm_sk = MiniBatchKMeans_sk(n_clusters=3, init=centers_init, n_init=1,random_state=42)\n",
    "\n",
    "mbkm_sk.fit(X_train)\n",
    "mbkm_sk.cluster_centers_ = sort_centers(mbkm_sk.cluster_centers_)\n",
    "mbkm_sk.predict(X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmfLQxuFdacK"
   },
   "source": [
    "## SIMBSIG\n",
    "### Using numpy arrays and CPU only\n",
    "SIMBSIG can be used very similar to scikit-learn. In an existing workflow using scikit-learn, which may be on the verge of exceeding runtime or memory requirements, this allows a seamless transition to SIMBSIG. Notice that when using different methods for KMeans clustering, the labels assigned to the clusters may be of different order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1655383427281,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "zXaewA5zdc5_",
    "outputId": "d3bf1b52-9936-469a-819a-a856b778399b"
   },
   "outputs": [],
   "source": [
    "mbkm = MiniBatchKMeans(n_clusters=3, init=centers_init, random_state=42)\n",
    "\n",
    "mbkm.fit(X_train)\n",
    "mbkm.cluster_centers_ = sort_centers(mbkm.cluster_centers_)\n",
    "mbkm.predict(X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY76CARJd8ay"
   },
   "source": [
    "### Using hdf5 files and CPU only\n",
    "If saving the entire data at once in the computer memory using numpy arrays is not reasonable anymore, the hdf5 file format can help. SIMBSIG can use data in hdf5 files, by setting the `mode` argument to `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "error",
     "timestamp": 1655383430291,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "dwTd5Zx7eDQL",
    "outputId": "69903339-f2ae-4d71-df60-816bba6a5963"
   },
   "outputs": [],
   "source": [
    "mbkm_hdf5 = MiniBatchKMeans(n_clusters=3, init=centers_init, mode='hdf5', random_state=42)\n",
    "\n",
    "# open the hdf5 file for use\n",
    "train_data = h5py.File(os.path.join(dataset_path, train_file), 'r')\n",
    "query_data = h5py.File(os.path.join(dataset_path, query_file))\n",
    "\n",
    "mbkm_hdf5.fit(train_data)\n",
    "mbkm_hdf5.cluster_centers_ = sort_centers(mbkm_hdf5.cluster_centers_)\n",
    "pred = mbkm_hdf5.predict(query_data)\n",
    "\n",
    "# close hdf5 files\n",
    "train_data.close()\n",
    "query_data.close()\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaQ8U_5NgSFu"
   },
   "source": [
    "### Using GPU acceleration\n",
    "If data gets big, the execution time becomes an issue. SIMBSIG features GPU acceleration, by setting the `device` argument to `gpu`. This works with both inputs, numpy arrays and hdf5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1655383392757,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "tXezDGmtgOuB"
   },
   "outputs": [],
   "source": [
    "mbkm_hdf5_gpu = MiniBatchKMeans(n_neighbors=2, mode='hdf5', device='gpu', tol=1e-8, max_iter=500, init=centers_init, random_state=42)\n",
    "\n",
    "# open the hdf5 file for use\n",
    "train_data = h5py.File(os.path.join(dataset_path, train_file), 'r')\n",
    "query_data = h5py.File(os.path.join(dataset_path, query_file))\n",
    "\n",
    "mbkm_hdf5_gpu.fit(train_data)\n",
    "mbkm_hdf5_gpu.cluster_centers_ = sort_centers(mbkm_hdf5_gpu.cluster_centers_)\n",
    "pred = mbkm_hdf5_gpu.predict(query_data)\n",
    "\n",
    "# close hdf5 files\n",
    "train_data.close()\n",
    "query_data.close()\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNGUXIklmMtVGuw6veoa8Hs",
   "collapsed_sections": [],
   "name": "MiniBatchKMeans_Demo.ipynb",
   "provenance": [
    {
     "file_id": "1JPp6MPPMrx5HiBvM2fqvW0dBJ3ElDihQ",
     "timestamp": 1655368771877
    },
    {
     "file_id": "1qqv5ubojhabGvbhLvd8foNpnNMuCxM9K",
     "timestamp": 1655368393627
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
