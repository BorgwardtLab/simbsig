{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdMO6zbMbIcB"
   },
   "source": [
    "# KNeighborsRegressor Demo\n",
    "This demo illustrates how SIMBSIG can be used for Nearest Neighbors queries, and how the use compares to scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simbsig in /home/eljas/anaconda3/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.22.4)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.9.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.9.1)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.7.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (3.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.1.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (3.0.0)\n",
      "Requirement already satisfied: typing_extensions in /home/eljas/anaconda3/lib/python3.8/site-packages (from torch<2.0.0,>=1.9.0->simbsig) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install simbsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1655372299453,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "7AbLEIDAaoBZ"
   },
   "outputs": [],
   "source": [
    "from simbsig.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNeighborsRegressor_sk\n",
    "import h5py as h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN436qeJaqbP"
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1655372299458,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "YhjxgUO_b_Ib"
   },
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "n_train_samples = 10\n",
    "n_query_samples = 5\n",
    "ylow = 0\n",
    "yhigh = 10\n",
    "n_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fInMHdVicL73"
   },
   "source": [
    "## Create Toy Data\n",
    "### numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1655372299461,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "JnsKWphqcQDd"
   },
   "outputs": [],
   "source": [
    "# numpy arrays\n",
    "X_train = np.random.uniform(low=-5, high=5, size=(n_train_samples, n_dim))\n",
    "X_query = np.random.uniform(low=-5, high=5, size=(n_query_samples, n_dim))\n",
    "y_train = np.random.randint(low=ylow, high=yhigh, size=(n_train_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNBiETAa3jr3"
   },
   "source": [
    "### hdf5 files\n",
    "#### Google Colab\n",
    "If you work from google colab, you can execute the statement below: Of course you can also store the data in a directory more suitable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14642,
     "status": "ok",
     "timestamp": 1655372314075,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "QtVlG3SG3s-A",
    "outputId": "2b7b80e5-a335-4702-9e4d-684017b33275"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10820/3391438261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# when working on colab, google drive can be used to save and read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# depending on the structure of your google drive, you might want to choose a different dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# when working on colab, google drive can be used to save and read data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# depending on the structure of your google drive, you might want to choose a different dataset path\n",
    "dataset_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Computer\n",
    "Alternatively, if you work from your computer, you can execute the statement below: Of course you can also store the data in a directory more suitable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working from your computer, your disk can be used to save and read data\n",
    "import os\n",
    "dataset_path = os.path.dirname(os.path.realpath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1655372314076,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "P-GKEsOs3nRn"
   },
   "outputs": [],
   "source": [
    "# hdf5 files using h5py\n",
    "train_file = f'train.hdf5'\n",
    "query_file = f'query.hdf5'\n",
    "\n",
    "with h5py.File(os.path.join(dataset_path, f\"{train_file}\"), 'w') as f:\n",
    "    f.create_dataset(\"X\", data=X_train)\n",
    "    f.create_dataset(\"y\",data=y_train)\n",
    "\n",
    "with h5py.File(os.path.join(dataset_path, f\"{query_file}\"), 'w') as f:\n",
    "    f.create_dataset(\"X\", data=X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSm9Qw5hcpf8"
   },
   "source": [
    "## Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1655372314077,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "Snfeo9fycUIr",
    "outputId": "27764eeb-fa4b-4581-d1a1-2fc5b2f57403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 8., 8., 5., 8.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sk = KNeighborsRegressor_sk(n_neighbors=2)\n",
    "\n",
    "nn_sk.fit(X_train, y_train)\n",
    "nn_sk.predict(X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmfLQxuFdacK"
   },
   "source": [
    "## SIMBSIG\n",
    "### Using numpy arrays and CPU only\n",
    "SIMBSIG can be used very similar to scikit-learn. In an existing workflow using scikit-learn, which may be on the verge of exceeding runtime or memory requirements, this allows a seamless transition to SIMBSIG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1655372314078,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "zXaewA5zdc5_",
    "outputId": "24cf2c24-ca45-46c1-e789-ec07c16b0efb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X_query progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "X_train for X_query progress:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                   \u001b[A\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 8., 8., 5., 8.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "nn.predict(X_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY76CARJd8ay"
   },
   "source": [
    "### Using hdf5 files and CPU only\n",
    "If saving the entire data at once in the computer memory using numpy arrays is not reasonable anymore, the hdf5 file format can help. SIMBSIG can use data in hdf5 files, by setting the `mode` argument to `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1655372314079,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "dwTd5Zx7eDQL",
    "outputId": "56e53ebc-b054-4ba0-cc49-b72610fa908f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X_query progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "X_train for X_query progress:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                   \u001b[A\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 8., 8., 5., 8.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_hdf5 = KNeighborsRegressor(n_neighbors=2, mode='hdf5')\n",
    "\n",
    "# open the hdf5 file for use\n",
    "train_data = h5py.File(os.path.join(dataset_path, train_file), 'r')\n",
    "query_data = h5py.File(os.path.join(dataset_path, query_file))\n",
    "\n",
    "nn_hdf5.fit(train_data)\n",
    "pred = nn_hdf5.predict(query_data)\n",
    "\n",
    "# close hdf5 file\n",
    "train_data.close()\n",
    "query_data.close()\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaQ8U_5NgSFu"
   },
   "source": [
    "### Using GPU acceleration\n",
    "If data gets big, the execution time becomes an issue. SIMBSIG features GPU acceleration, by setting the `device` argument to `gpu`. This works with both inputs, numpy arrays and hdf5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3719,
     "status": "ok",
     "timestamp": 1655372317781,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "tXezDGmtgOuB",
    "outputId": "0e4db9f4-30d5-4bec-f0d8-2f8c8f5a5f49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10820/1331097223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnn_hdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_hdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# close hdf5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/simbsig/neighbors/KNeighborsRegressor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Calling predict without query matrix X as argument only allowed if metric=='precomputed'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/simbsig/base/_base.py\u001b[0m in \u001b[0;36m_kneighbors\u001b[0;34m(self, X_query, n_neighbors, return_distance, sort_results)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Move query batch to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mX_query_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_query_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mneigh_dist_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_query_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "nn_hdf5 = KNeighborsRegressor(n_neighbors=2, mode='hdf5', device='gpu')\n",
    "\n",
    "# open the hdf5 file for use\n",
    "train_data = h5py.File(os.path.join(dataset_path, train_file), 'r')\n",
    "query_data = h5py.File(os.path.join(dataset_path, query_file))\n",
    "\n",
    "nn_hdf5.fit(train_data)\n",
    "pred = nn_hdf5.predict(query_data)\n",
    "\n",
    "# close hdf5 file\n",
    "train_data.close()\n",
    "query_data.close()\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPi22Q+4YE/q2h9L9403StF",
   "collapsed_sections": [],
   "name": "KNeighborsRegressor_Demo.ipynb",
   "provenance": [
    {
     "file_id": "1qqv5ubojhabGvbhLvd8foNpnNMuCxM9K",
     "timestamp": 1655367561956
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
