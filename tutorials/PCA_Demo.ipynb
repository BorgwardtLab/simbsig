{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdMO6zbMbIcB"
   },
   "source": [
    "# PCA Demo\n",
    "This demo illustrates how SIMBSIG can be used for Principal Component Analysis (PCA), and how the use compares to scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simbsig in /home/eljas/anaconda3/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.1.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.1.1)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.9.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.12.0)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.7.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (3.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (4.64.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from simbsig) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (3.0.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/eljas/anaconda3/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.0->simbsig) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /home/eljas/anaconda3/lib/python3.8/site-packages (from torch<2.0.0,>=1.9.0->simbsig) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install simbsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1655374792088,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "7AbLEIDAaoBZ"
   },
   "outputs": [],
   "source": [
    "from simbsig.decomposition import PCA\n",
    "from sklearn.decomposition import PCA as PCA_sk\n",
    "import h5py as h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN436qeJaqbP"
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1655374792092,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "YhjxgUO_b_Ib"
   },
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "n_samples = 20\n",
    "n_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fInMHdVicL73"
   },
   "source": [
    "## Create Toy Data\n",
    "### numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1655374792095,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "JnsKWphqcQDd"
   },
   "outputs": [],
   "source": [
    "# numpy arrays\n",
    "X = np.random.uniform(low=-5, high=5, size=(n_samples, n_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fXkBXPt6TFa"
   },
   "source": [
    "### hdf5 files\n",
    "#### Google Colab\n",
    "If you work from google colab, you can execute the statement below: Of course you can also store the data in a directory more suitable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1655374794165,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "OFuQ46QJ6bSh",
    "outputId": "3a884c60-6812-4a39-baf3-e2c601718c6c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19010/3391438261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# when working on colab, google drive can be used to save and read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# depending on the structure of your google drive, you might want to choose a different dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# when working on colab, google drive can be used to save and read data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# depending on the structure of your google drive, you might want to choose a different dataset path\n",
    "dataset_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Computer\n",
    "Alternatively, if you work from your computer, you can execute the statement below:\n",
    "Of course you can also store the data in a directory more suitable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working from your computer, your disk can be used to save and read data\n",
    "import os\n",
    "dataset_path = os.path.dirname(os.path.realpath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1655374794167,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "_6H8mHSe6YSw"
   },
   "outputs": [],
   "source": [
    "# hdf5 files using h5py\n",
    "X_file = f'train.hdf5'\n",
    "\n",
    "with h5py.File(os.path.join(dataset_path, f\"{X_file}\"), 'w') as f:\n",
    "    f.create_dataset(\"X\", data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSm9Qw5hcpf8"
   },
   "source": [
    "## Scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1655374794168,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "Snfeo9fycUIr",
    "outputId": "3dca27a9-d317-430c-ec36-0b1cc74f2a71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.58473104,  0.79893721],\n",
       "       [-0.92822381,  0.28984871],\n",
       "       [ 1.80687758,  0.74262492],\n",
       "       [ 4.08544446,  1.71724538],\n",
       "       [-3.95675763, -3.44066341],\n",
       "       [-4.43290221, -2.36003492],\n",
       "       [-4.27286936, -2.0032996 ],\n",
       "       [-1.62268984,  5.66375729],\n",
       "       [ 6.15953168,  0.132802  ],\n",
       "       [-5.54501202,  2.07147302],\n",
       "       [-3.02132808, -0.12196357],\n",
       "       [-1.30904908, -3.21932466],\n",
       "       [ 2.49030777,  2.06508366],\n",
       "       [-5.72565927,  3.44920117],\n",
       "       [ 4.07681933, -1.86069684],\n",
       "       [ 5.19637105,  3.06962547],\n",
       "       [ 3.17831714, -2.71930587],\n",
       "       [-0.36333476,  0.62327764],\n",
       "       [ 1.06274721, -3.83762988],\n",
       "       [ 4.70614087, -1.0609577 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sk = PCA_sk(n_components=2)\n",
    "\n",
    "pca_sk.fit(X)\n",
    "pca_sk.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmfLQxuFdacK"
   },
   "source": [
    "## SIMBSIG\n",
    "### Using numpy arrays and CPU only\n",
    "SIMBSIG can be used very similar to scikit-learn. In an existing workflow using scikit-learn, which may be on the verge of exceeding runtime or memory requirements, this allows a seamless transition to SIMBSIG. Notice that when using different methods for PCA, the principal components may have a different sign.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1655374794617,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "zXaewA5zdc5_",
    "outputId": "d40bb4bf-3d09-4bc1-db08-8e787edac52b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.584731  , -0.79894   ],\n",
       "       [-0.9282242 , -0.28985322],\n",
       "       [ 1.8068779 , -0.74262524],\n",
       "       [ 4.0854454 , -1.7172432 ],\n",
       "       [-3.956759  ,  3.4406645 ],\n",
       "       [-4.4329033 ,  2.3600342 ],\n",
       "       [-4.27287   ,  2.0032988 ],\n",
       "       [-1.6226879 , -5.6637545 ],\n",
       "       [ 6.159532  , -0.13280044],\n",
       "       [-5.545012  , -2.0714743 ],\n",
       "       [-3.0213284 ,  0.1219622 ],\n",
       "       [-1.3090497 ,  3.2193284 ],\n",
       "       [ 2.490309  , -2.0650814 ],\n",
       "       [-5.7256584 , -3.4492006 ],\n",
       "       [ 4.076819  ,  1.8606944 ],\n",
       "       [ 5.196372  , -3.069625  ],\n",
       "       [ 3.1783173 ,  2.719311  ],\n",
       "       [-0.36333475, -0.62327933],\n",
       "       [ 1.0627458 ,  3.837627  ],\n",
       "       [ 4.706141  ,  1.0609591 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X)\n",
    "pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY76CARJd8ay"
   },
   "source": [
    "### Using hdf5 files and CPU only\n",
    "If saving the entire data at once in the computer memory using numpy arrays is not reasonable anymore, the hdf5 file format can help. SIMBSIG can use data in hdf5 files, by setting the `mode` argument to `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1655374794620,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "dwTd5Zx7eDQL",
    "outputId": "dc6db398-a1ef-4f54-9491-b1c21a48ca50",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.584731  , -0.798935  ],\n",
       "       [-0.92822397, -0.28984517],\n",
       "       [ 1.8068776 , -0.7426246 ],\n",
       "       [ 4.0854445 , -1.7172467 ],\n",
       "       [-3.9567575 ,  3.440663  ],\n",
       "       [-4.4329023 ,  2.3600357 ],\n",
       "       [-4.272869  ,  2.0033002 ],\n",
       "       [-1.6226906 , -5.6637588 ],\n",
       "       [ 6.159532  , -0.13280292],\n",
       "       [-5.5450125 , -2.0714724 ],\n",
       "       [-3.0213282 ,  0.12196495],\n",
       "       [-1.3090488 ,  3.2193215 ],\n",
       "       [ 2.490308  , -2.0650852 ],\n",
       "       [-5.7256603 , -3.4492004 ],\n",
       "       [ 4.07682   ,  1.8606987 ],\n",
       "       [ 5.1963706 , -3.0696254 ],\n",
       "       [ 3.1783178 ,  2.719302  ],\n",
       "       [-0.36333486, -0.6232762 ],\n",
       "       [ 1.0627477 ,  3.8376315 ],\n",
       "       [ 4.7061415 ,  1.0609567 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_hdf5 = PCA(n_components=2, mode='hdf5')\n",
    "\n",
    "# open the hdf5 file for use\n",
    "X_data = h5py.File(os.path.join(dataset_path, X_file), 'r')\n",
    "\n",
    "pca_hdf5.fit(X_data)\n",
    "trafo = pca_hdf5.transform(X_data)\n",
    "\n",
    "# close hdf5 file\n",
    "X_data.close()\n",
    "\n",
    "trafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaQ8U_5NgSFu"
   },
   "source": [
    "### Using GPU acceleration\n",
    "If data gets big, the execution time becomes an issue. SIMBSIG features GPU acceleration, by setting the `device` argument to `gpu`. This works with both inputs, numpy arrays and hdf5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5996,
     "status": "ok",
     "timestamp": 1655374800602,
     "user": {
      "displayName": "E. R.",
      "userId": "08172683547117167723"
     },
     "user_tz": -120
    },
    "id": "tXezDGmtgOuB",
    "outputId": "3898b8ec-3f8d-4959-b548-e2b50206db42"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12385/2978531512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpca_hdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrafo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_hdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/simbsig/decomposition/PCA.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     num_workers=self.n_jobs)\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "pca_hdf5 = PCA(n_components=2, mode='hdf5', device='gpu')\n",
    "\n",
    "# open the hdf5 file for use\n",
    "X_data = h5py.File(os.path.join(dataset_path, X_file), 'r')\n",
    "\n",
    "pca_hdf5.fit(X_data)\n",
    "trafo = pca_hdf5.transform(X_data)\n",
    "\n",
    "# close hdf5 file\n",
    "X_data.close()\n",
    "\n",
    "trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNumSqd4jLD9PAQlirnHX9l",
   "collapsed_sections": [],
   "name": "PCA_Demo.ipynb",
   "provenance": [
    {
     "file_id": "1qqv5ubojhabGvbhLvd8foNpnNMuCxM9K",
     "timestamp": 1655368393627
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
